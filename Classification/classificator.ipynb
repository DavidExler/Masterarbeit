{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ca8aae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Welcome to CellposeSAM, cellpose v\n",
      "cellpose version: \t4.0.4 \n",
      "platform:       \tlinux \n",
      "python version: \t3.11.0rc1 \n",
      "torch version:  \t2.6.0+cu124! The neural network component of\n",
      "CPSAM is much larger than in previous versions and CPU excution is slow. \n",
      "We encourage users to use GPU/MPS if available. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from cellpose import models, core, io, plot\n",
    "from pathlib import Path\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "from natsort import natsorted\n",
    "import tifffile\n",
    "import pickle\n",
    "from helpers.visualization_helper import extract_contours_from_mask, plot_image_with_clustered_contours_RGB\n",
    "from helpers.features_helper import cluster_features, extract_features_and_contours\n",
    "import json\n",
    "\n",
    "imgs_20xRenamed = []\n",
    "with open('save_data/3D_images_Renamed/imgs_20xRenamed.pkl', 'rb') as f:\n",
    "    imgs_20xRenamed = pickle.load(f)\n",
    "masks_20xRenamed = []\n",
    "with open('save_data/masks/20xRenamed/masks3D_CELLPOSE_RUN_1.pkl', 'rb') as f:\n",
    "    masks_20xRenamed = pickle.load(f)\n",
    "final_classes = {}\n",
    "with open(\"classes_0.json\", \"r\") as f:\n",
    "    final_classes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5ea5f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1024, 1024)\n",
      "(1024, 1024, 2)\n",
      "(1024, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "image_index = 13\n",
    "slice = 15\n",
    "mask = masks_20xRenamed[image_index][slice,:,:]\n",
    "img = imgs_20xRenamed[image_index][slice, 0:2, :, :]\n",
    "print(img.shape)\n",
    "img_reshaped = img.transpose(1, 2, 0) \n",
    "print(img_reshaped.shape)\n",
    "img_rgb = np.concatenate([img_reshaped.astype(np.uint8), np.zeros((1024, 1024, 1), dtype=np.uint8)], axis=2)\n",
    "print(img_rgb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d0093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 0\n",
    "mask = masks_20xRenamed[image_index]\n",
    "classes = {}\n",
    "slices = mask.shape[0]\n",
    "for s in range(slices): \n",
    "    print(f\"Processing slice {s} of {slices} of image {image_index}\")\n",
    "    contours_with_features = extract_features_and_contours(mask[s, :, :])\n",
    "    contours_with_classes = cluster_features(contours_with_features, k=5)\n",
    "    print(\"Number of contours with classes:\", len(contours_with_classes))\n",
    "    for label in contours_with_classes:\n",
    "        if label == 0:\n",
    "            continue\n",
    "        obj_class = contours_with_classes[label]['class']\n",
    "        \n",
    "        if label not in classes:\n",
    "            classes[label] = []\n",
    "        classes[label].append(obj_class)\n",
    "\n",
    "# Optionally, convert sets to lists if you need to serialize or inspect\n",
    "#classes = {k: list(v) for k, v in classes.items()}\n",
    "#print(\"Classes per object ID:\")\n",
    "#for obj_id, obj_classes in classes.items():\n",
    "#    print(f\"Object ID {obj_id}: Classes {obj_classes}\")\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fc093235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "final_classes = {}\n",
    "\n",
    "for obj_id, obj_classes in classes.items():\n",
    "    trimmed = obj_classes[:]\n",
    "    \n",
    "    # Keep trimming until â‰¤ 4 or no change\n",
    "    while len(trimmed) > 4:\n",
    "        trimmed = trimmed[1:-1]\n",
    "        if len(trimmed) <= 4:\n",
    "            break\n",
    "\n",
    "    counter = Counter(trimmed)\n",
    "    most_common = counter.most_common()\n",
    "\n",
    "    if len(most_common) == 1:\n",
    "        final_class = most_common[0][0]\n",
    "    else:\n",
    "        top_freq = most_common[0][1]\n",
    "        tied_classes = [cls for cls, freq in most_common if freq == top_freq]\n",
    "        \n",
    "        if len(tied_classes) == 1:\n",
    "            final_class = tied_classes[0]\n",
    "        else:\n",
    "            final_class = random.choice(tied_classes)\n",
    "    \n",
    "    final_classes[int(obj_id)] = final_class\n",
    "\n",
    "\n",
    "# Save to JSON\n",
    "with open(\"classes_0.json\", \"w\") as f:\n",
    "    json.dump(final_classes, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaa91be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "with open(\"classes_0.json\", \"r\") as f:\n",
    "    final_classes = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e08c9735",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'contours_with_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNumber of contours with features:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mcontours_with_features\u001b[49m))\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNumber of contours with classes:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(contours_with_classes))\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#print(\"First contour with classes:\", contours_with_classes[1]['class'])\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#print(\"First contour with classes:\", contours_with_classes[1].keys())\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'contours_with_features' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Number of contours with features:\", len(contours_with_features))\n",
    "print(\"Number of contours with classes:\", len(contours_with_classes))\n",
    "#print(\"First contour with classes:\", contours_with_classes[1]['class'])\n",
    "#print(\"First contour with classes:\", contours_with_classes[1].keys())\n",
    "print(len(np.unique(mask)))\n",
    "#for data in contours_with_classes:\n",
    "#    print(contours_with_classes[data]['class'])\n",
    "#    #print(data['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416f6324",
   "metadata": {},
   "source": [
    "# Experiment with different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35710565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import DenseNet121, resnet18\n",
    "import torch.nn as nn\n",
    "from Classification.classifier_helper import ClassificatorBlobHelper\n",
    "\n",
    "# Example with DenseNet\n",
    "VERSION = 1\n",
    "densenet_model = DenseNet121(spatial_dims=3, in_channels=2+VERSION, out_channels=5) \n",
    "blb = ClassificatorBlobHelper()\n",
    "blb.version = VERSION\n",
    "\n",
    "# Example with ResNet\n",
    "resnet_model = resnet18(spatial_dims=3, n_input_channels=3, num_classes=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a857831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "gt_classes = {}\n",
    "with open(\"classes_0.json\", \"r\") as f:\n",
    "    gt_classes = json.load(f)\n",
    "\n",
    "print(gt_classes[\"12\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3883c75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 1899\n",
      "Train dataset 0, 0: torch.Size([3, 32, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from Classification.classifier_helper import ObjectPatchDataset, calculate_test_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "from monai.transforms import (\n",
    "    Compose, RandRotate90, RandFlip, RandGaussianNoise,\n",
    "    EnsureType, EnsureChannelFirst\n",
    ")\n",
    "\n",
    "train_transforms = Compose([\n",
    "    RandRotate90(prob=0.5, spatial_axes=(0, 1)),  # rotate in XY\n",
    "    RandFlip(prob=0.5, spatial_axis=0),           # flip on Z\n",
    "    RandGaussianNoise(prob=0.2, mean=0.0, std=0.01),\n",
    "    EnsureType()  # Makes sure it's a torch.Tensor\n",
    "])\n",
    "\n",
    "\n",
    "image_index = 0 # potentially add more images as a list\n",
    "label_indices = [int(i) for i in np.unique(masks_20xRenamed[image_index]) if i != 0]\n",
    "\n",
    "#for image_index in range(len(masks_20xRenamed)):\n",
    "#    all_indices = [(image_index, i) for i in label_indices]\n",
    "all_indices = [(0, i) for i in label_indices]   \n",
    "all_labels = [gt_classes[str(i)] for i in label_indices]\n",
    "\n",
    "train_idx, val_idx, train_lbls, val_lbls = train_test_split(all_indices, all_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = ObjectPatchDataset(blb, train_idx, train_lbls, transform=train_transforms)\n",
    "val_dataset = ObjectPatchDataset(blb, val_idx, val_lbls)  # no augmentation\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Train dataset 0, 0: {train_dataset[0][0].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac54599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model_version = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "history = {\"loss\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "model = resnet_model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "checkpoint_dir = \"save_data/checkpoints\"\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Debug shapes\n",
    "        print(f\"Epoch {epoch}, Batch {batch_idx}: X = {X.shape}, y = {y.shape}\")\n",
    "\n",
    "        # Forward\n",
    "        pred = model(X)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    val_loss, val_acc = calculate_test_loss(model, val_loader, criterion, device)\n",
    "    print(f\"[Epoch {epoch+1}/{num_epochs}]: Avg_loss = {avg_loss}, Val Loss = {val_loss:.4f}, Val Acc = {val_acc:.4f}\")\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    history[\"loss\"].append(avg_loss)\n",
    "    history[\"val_loss\"].append(val_loss)    \n",
    "    history[\"val_acc\"].append(val_acc)    \n",
    "    #print(f\"[Epoch {epoch+1}/{num_epochs}] Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # ðŸ”½ Save model checkpoint (overwrite to save space)\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"model_v{model_version}.pt\")\n",
    "    torch.save({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"loss\": avg_loss,\n",
    "    }, checkpoint_path)\n",
    "    print(f\"Saved checkpoint: {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d55871a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "# Move model to CPU and delete\n",
    "model = model.to(\"cpu\")\n",
    "del model\n",
    "\n",
    "# Empty cache and collect garbage\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "931334f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\"loss\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "history[\"loss\"].append(1)\n",
    "history[\"val_loss\"].append(1)    \n",
    "history[\"val_acc\"].append(1)    \n",
    "history[\"loss\"].append(2)\n",
    "history[\"val_loss\"].append(2)    \n",
    "history[\"val_acc\"].append(2)    \n",
    "history[\"loss\"].append(3)\n",
    "history[\"val_loss\"].append(3)    \n",
    "history[\"val_acc\"].append(3)\n",
    "\n",
    "import os\n",
    "checkpoint_dir = \"save_data/checkpoints\"\n",
    "history_path = os.path.join(checkpoint_dir, f\"history_v{VERSION}.json\")\n",
    "import json\n",
    "with open(history_path, \"w\") as f:\n",
    "    json.dump(history, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1c47ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.5255147602683619, 0.36)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training Curve\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d7956f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 2, 1024, 1024)\n",
      "(2, 1024, 1024, 28)\n",
      "(1024, 1024, 28)\n",
      "(1, 1024, 1024, 28)\n",
      "(3, 1024, 1024, 28)\n"
     ]
    }
   ],
   "source": [
    "image_index = 0\n",
    "mask = masks_20xRenamed[image_index]\n",
    "img = imgs_20xRenamed[image_index][:, 0:2, :, :]\n",
    "print(img.shape)\n",
    "img_reshaped = img.transpose(1, 2, 3, 0) \n",
    "mask_reshaped = mask.transpose(1, 2, 0) \n",
    "print(img_reshaped.shape)\n",
    "print(mask_reshaped.shape)\n",
    "zeros = np.zeros((1, 1024, 1024, img_reshaped.shape[3]), dtype=np.uint8)\n",
    "print(zeros.shape)\n",
    "img_rgb = np.concatenate([img_reshaped.astype(np.uint8), zeros], axis=0)\n",
    "print(img_rgb.shape)\n",
    "img_rgb[2,:,:,:] = (mask_reshaped > 0) * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c84adde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.blob.shape: (28, 1024, 1024)\n",
      "final_blob.shape: (3, 64, 64, 28)\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import Classification.classifier_helper\n",
    "importlib.reload(Classification.classifier_helper)\n",
    "from Classification.classifier_helper import ClassificatorBlobHelper, preprocess_blob\n",
    "\n",
    "blb = ClassificatorBlobHelper()\n",
    "blob, oob = blb.get_blob(0,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9076a0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 64, 64, 28)\n"
     ]
    }
   ],
   "source": [
    "print(blob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13937e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "blob, oob = blb.get_blob(0,4, in_channel_dist=False, gaus_exp_nuc=20.0)\n",
    "plt.imshow(blob[(0,1,3),:,:,10].transpose(1, 2, 0))\n",
    "plt.show()\n",
    "plt.imshow(blob[0,:,:,10])\n",
    "plt.show()\n",
    "plt.imshow(blob[1,:,:,10])\n",
    "plt.show()\n",
    "plt.imshow(blob[2,:,:,10])\n",
    "plt.show()\n",
    "plt.imshow(blob[3,:,:,10])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d6b828",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob, oob = blb.get_blob(0,4, in_channel_dist=True, gaus_exp_nuc=10.0, gaus_exp_myo=20.0)\n",
    "#plt.imshow(blob[:,:,:,10].transpose(1, 2, 0))\n",
    "#plt.show()\n",
    "plt.imshow(blob[0,:,:,10])\n",
    "plt.show()\n",
    "plt.imshow(blob[1,:,:,10])\n",
    "plt.show()\n",
    "plt.imshow(blob[2,:,:,10])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24fa61ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'classifier_helper' from '/Users/davidexler/Documents/Masterarbeit/repo/Masterarbeit/Classification/classifier_helper.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import classifier_helper #import SAMClassifier3D_CENTER_AWARE, get_resnet18_encoder, get_swinl_encoder, get_convnextxl_encoder, get_efficientnetv2l_encoder, get_resnet101_encoder\n",
    "\n",
    "importlib.reload(classifier_helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d08aba71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifier_helper import SAMClassifier3D_CENTER_AWARE, get_resnet18_encoder, get_swinl_encoder, get_convnextxl_encoder, get_efficientnetv2l_encoder, get_resnet101_encoder\n",
    "import torch\n",
    "#enc = get_resnet18_encoder() #WORKING\n",
    "#enc = get_resnet101_encoder() #WORKING\n",
    "#enc = get_swinl_encoder() #WORKING\n",
    "#enc = get_convnextxl_encoder() #WORKING\n",
    "enc = get_efficientnetv2l_encoder() #WORKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bd199f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Input shape: torch.Size([1, 3, 32, 256, 256])\n",
      "[DEBUG] Ecoder-Input shape: torch.Size([32, 3, 256, 256])\n",
      "[DEBUG] Ecoder-Output shape: torch.Size([32, 3, 256, 256])\n",
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "dim = 256\n",
    "X_random_3D = torch.randn((1,3,32,dim,dim))\n",
    "X_random_2D = torch.randn((1,3,dim,dim))\n",
    "test_model = SAMClassifier3D_CENTER_AWARE(enc, 5, False, False)\n",
    "cls = test_model(X_random_3D)\n",
    "print(cls.shape)\n",
    "#[DEBUG] Input shape: torch.Size([1, 3, 32, 256, 256])\n",
    "#[DEBUG] Ecoder-Input shape: torch.Size([32, 3, 256, 256])\n",
    "#[DEBUG] Ecoder-Output shape: torch.Size([32, 3, 256, 256])\n",
    "#torch.Size([1, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07111515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 32, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "print(test_model.out_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc15a94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinTransformer(\n",
      "  (features): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (1): Permute()\n",
      "      (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
      "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=4, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
      "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=512, out_features=128, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
      "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=4, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.021739130434782608, mode=row)\n",
      "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=512, out_features=128, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): PatchMergingV2(\n",
      "      (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
      "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=8, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.043478260869565216, mode=row)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=8, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.06521739130434782, mode=row)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): PatchMergingV2(\n",
      "      (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.08695652173913043, mode=row)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.10869565217391304, mode=row)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.15217391304347827, mode=row)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.17391304347826086, mode=row)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1956521739130435, mode=row)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.21739130434782608, mode=row)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.2391304347826087, mode=row)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.2608695652173913, mode=row)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.2826086956521739, mode=row)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.30434782608695654, mode=row)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.32608695652173914, mode=row)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (12): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.34782608695652173, mode=row)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (13): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.3695652173913043, mode=row)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (14): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.391304347826087, mode=row)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (15): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.41304347826086957, mode=row)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (16): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.43478260869565216, mode=row)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (17): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.45652173913043476, mode=row)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): PatchMergingV2(\n",
      "      (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
      "      (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=32, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.4782608695652174, mode=row)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=32, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.5, mode=row)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  (permute): Permute()\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (head): Linear(in_features=1024, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e5b0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
