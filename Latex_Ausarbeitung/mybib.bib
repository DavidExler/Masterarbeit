@article{dosovitskiy2020ViT,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{he2022mae,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={16000--16009},
  year={2022}
}

@misc{jrfarm_katze,
  author       = {{JR Farm}},
  title        = {Katzenratgeber – Alles Wissenswerte über Katzen},
  year         = 2025,
  howpublished = {\url{https://www.jr-farm.de/ratgeber/tiere/katze}},
  note         = {Accessed: 2025-06-26}
}

@misc{Egan_Katzen,
author = {Egan, Ben and Redden, Alex and {XWAVE} and {SilentAntagonist}},
month = may,
title = {{Dalle3 1 Million+ High Quality Captions}},
url = {https://huggingface.co/datasets/ProGamerGov/synthetic-dataset-1m-dalle3-high-quality-captions},
year = {2024}
}

%nuclei datensatz papers
@article{edlund2021livecell,
  title={LIVECell—A large-scale dataset for label-free live cell segmentation},
  author={Edlund, Christoffer and Jackson, Timothy R and Khalid, Nabeel and Bevan, Nicola and Dale, Timothy and Dengel, Andreas and Ahmed, Sheraz and Trygg, Johan and Sj{\"o}gren, Rickard},
  journal={Nature methods},
  volume={18},
  number={9},
  pages={1038--1045},
  year={2021},
  publisher={Nature Publishing Group US New York}
}

@article{dietler2020YeaZ,
  title={A convolutional neural network segments yeast microscopy images with high accuracy},
  author={Dietler, Nicola and Minder, Matthias and Gligorovski, Vojislav and Economou, Augoustina Maria and Joly, Denis Alain Henri Lucien and Sadeghi, Ahmad and Chan, Chun Hei Michael and Kozi{\'n}ski, Mateusz and Weigert, Martin and Bitbol, Anne-Florence and others},
  journal={Nature communications},
  volume={11},
  number={1},
  pages={5723},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{cutler2022omnipose,
  title={Omnipose: a high-precision morphology-independent solution for bacterial cell segmentation},
  author={Cutler, Kevin J and Stringer, Carsen and Lo, Teresa W and Rappez, Luca and Stroustrup, Nicholas and Brook Peterson, S and Wiggins, Paul A and Mougous, Joseph D},
  journal={Nature methods},
  volume={19},
  number={11},
  pages={1438--1448},
  year={2022},
  publisher={Nature Publishing Group US New York}
}

@misc{holden2021deepbacs,
  author       = {Holden, S. and Conduit, M.},
  title        = {{DeepBacs – Bacillus subtilis fluorescence segmentation dataset}},
  year         = {2021},
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.5550968},
  url          = {https://doi.org/10.5281/zenodo.5550968},
  note         = {Data set}
}

@article{cspahn2021deepbacs,
  title={DeepBacs: Bacterial image analysis using open-source deep learning approaches},
  author={Spahn, Christoph and Laine, Romain F. and Matos Pereira, Pedro and von Chamier, Lucas and Conduit, Mia and G{\'o}mez-de-Mariscal, Estibaliz and Gomes de Pinho, Mariana and Jacquemet, Guillaume and Holden, S{\'{e}}amus and Heilemann, Mike and Henriques, Ricardo},
  journal={bioRxiv},
  year={2021},
  doi = {10.1101/2021.11.03.467152},
  publisher = {Cold Spring Harbor Laboratory},
  URL = {https://www.biorxiv.org/content/early/2021/11/03/2021.11.03.467152}
}

@article{kumar2017MoNuSeg,
  title={A dataset and a technique for generalized nuclear segmentation for computational pathology},
  author={Kumar, Neeraj and Verma, Ruchika and Sharma, Sanuj and Bhargava, Surabhi and Vahadane, Abhishek and Sethi, Amit},
  journal={IEEE transactions on medical imaging},
  volume={36},
  number={7},
  pages={1550--1560},
  year={2017},
  publisher={IEEE}
}

@article{greenwald2022Tissuenet,
  title={Whole-cell segmentation of tissue images with human-level performance using large-scale data annotation and deep learning},
  author={Greenwald, Noah F and Miller, Geneva and Moen, Erick and Kong, Alex and Kagel, Adam and Dougherty, Thomas and Fullaway, Christine Camacho and McIntosh, Brianna J and Leow, Ke Xuan and Schwartz, Morgan Sarah and others},
  journal={Nature biotechnology},
  volume={40},
  number={4},
  pages={555--565},
  year={2022},
  publisher={Nature Publishing Group US New York}
}


%Domain adaption und similarity
@article{ganin2016domain,
  title={Domain-adversarial training of neural networks},
  author={Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, Fran{\c{c}}ois and March, Mario and Lempitsky, Victor},
  journal={Journal of machine learning research},
  volume={17},
  number={59},
  pages={1--35},
  year={2016}
}

@inproceedings{yuan2005domainsimilarity,
  title={An empirical study on language model adaptation using a metric of domain similarity},
  author={Yuan, Wei and Gao, Jianfeng and Suzuki, Hisami},
  booktitle={International Conference on Natural Language Processing},
  pages={957--968},
  year={2005},
  organization={Springer}
}

@inproceedings{ganin2015domain_big,
  title={Unsupervised domain adaptation by backpropagation},
  author={Ganin, Yaroslav and Lempitsky, Victor},
  booktitle={International conference on machine learning},
  pages={1180--1189},
  year={2015},
  organization={PMLR}
}

@inproceedings{pinheiro2018domain,
  title={Unsupervised domain adaptation with similarity learning},
  author={Pinheiro, Pedro O},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8004--8013},
  year={2018}
}

@article{peng2017domain,
  title={Visda: The visual domain adaptation challenge},
  author={Peng, Xingchao and Usman, Ben and Kaushik, Neela and Hoffman, Judy and Wang, Dequan and Saenko, Kate},
  journal={arXiv preprint arXiv:1710.06924},
  year={2017}
}

@article{wang2018domain,
  title={Deep visual domain adaptation: A survey},
  author={Wang, Mei and Deng, Weihong},
  journal={Neurocomputing},
  volume={312},
  pages={135--153},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{cai2009similarity,
  title={Efficient algorithm for computing link-based similarity in real world networks},
  author={Cai, Yuanzhe and Cong, Gao and Jia, Xu and Liu, Hongyan and He, Jun and Lu, Jiaheng and Du, Xiaoyong},
  booktitle={2009 Ninth IEEE International Conference on Data Mining},
  pages={734--739},
  year={2009},
  organization={IEEE}
}

@article{koohi2018similarity,
  title={Cross-domain graph based similarity measurement of workflows},
  author={Koohi-Var, Tahereh and Zahedi, Morteza},
  journal={Journal of Big Data},
  volume={5},
  pages={1--16},
  year={2018},
  publisher={Springer}
}

@article{han2022binsimilarity_domain,
  title={Bin similarity-based domain adaptation for fine-grained image classification},
  author={Han, Tianyu and Zhang, Lifeng and Jia, Shixiang},
  journal={International Journal of Intelligent Systems},
  volume={37},
  number={3},
  pages={2319--2334},
  year={2022},
  publisher={Wiley Online Library}
}

@article{zhu2020domain_similarity,
  title={Domain adaptation using class similarity for robust speech recognition},
  author={Zhu, Han and Zhao, Jiangjiang and Ren, Yuling and Wang, Li and Zhang, Pengyuan},
  journal={arXiv preprint arXiv:2011.02782},
  year={2020}
}

@article{bruch2025,
  title={Improving 3D deep learning segmentation with biophysically motivated cell synthesis},
  author={Bruch, Roman and Vitacolonna, Mario and N{\"u}rnberg, Elina and Sauer, Simeon and Rudolf, R{\"u}diger and Reischl, Markus},
  journal={Communications Biology},
  volume={8},
  number={1},
  pages={43},
  year={2025},
  publisher={Nature Publishing Group UK London}
}

%Segmentierung foundation model
@inproceedings{li2023mask,
  title={Mask dino: Towards a unified transformer-based framework for object detection and segmentation},
  author={Li, Feng and Zhang, Hao and Xu, Huaizhe and Liu, Shilong and Zhang, Lei and Ni, Lionel M and Shum, Heung-Yeung},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={3041--3050},
  year={2023}
}

@article{isensee2021nnu,
  title={nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation},
  author={Isensee, Fabian and Jaeger, Paul F and Kohl, Simon AA and Petersen, Jens and Maier-Hein, Klaus H},
  journal={Nature methods},
  volume={18},
  number={2},
  pages={203--211},
  year={2021},
  publisher={Nature Publishing Group}
}

%Segmentierung model
@article{moen2019DeepcellCaliban,
  title={Accurate cell tracking and lineage construction in live-cell imaging experiments with deep learning},
  author={Moen, Erick and Borba, Enrico and Miller, Geneva and Schwartz, Morgan and Bannon, Dylan and Koe, Nora and Camplisson, Isabella and Kyme, Daniel and Pavelchek, Cole and Price, Tyler and others},
  journal={Biorxiv},
  pages={803205},
  year={2019},
  publisher={Cold Spring Harbor Laboratory}
}

@article{bannon2021deepcell,
  title={DeepCell Kiosk: scaling deep learning--enabled cellular image analysis with Kubernetes},
  author={Bannon, Dylan and Moen, Erick and Schwartz, Morgan and Borba, Enrico and Kudo, Takamasa and Greenwald, Noah and Vijayakumar, Vibha and Chang, Brian and Pao, Edward and Osterman, Erik and others},
  journal={Nature methods},
  volume={18},
  number={1},
  pages={43--45},
  year={2021},
  publisher={Nature Publishing Group US New York}
}

@article{greenwald2022deepcell,
  title={Whole-cell segmentation of tissue images with human-level performance using large-scale data annotation and deep learning},
  author={Greenwald, Noah F and Miller, Geneva and Moen, Erick and Kong, Alex and Kagel, Adam and Dougherty, Thomas and Fullaway, Christine Camacho and McIntosh, Brianna J and Leow, Ke Xuan and Schwartz, Morgan Sarah and others},
  journal={Nature biotechnology},
  volume={40},
  number={4},
  pages={555--565},
  year={2022},
  publisher={Nature Publishing Group US New York}
}

@article{van2016deepcell,
  title={Deep learning automates the quantitative analysis of individual cells in live-cell imaging experiments},
  author={Van Valen, David A and Kudo, Takamasa and Lane, Keara M and Macklin, Derek N and Quach, Nicolas T and DeFelice, Mialy M and Maayan, Inbal and Tanouchi, Yu and Ashley, Euan A and Covert, Markus W},
  journal={PLoS computational biology},
  volume={12},
  number={11},
  pages={e1005177},
  year={2016},
  publisher={Public Library of Science San Francisco, CA USA}
}


%Segmentierung foundation model
@inproceedings{jain2023oneformer,
  title={Oneformer: One transformer to rule universal image segmentation},
  author={Jain, Jitesh and Li, Jiachen and Chiu, Mang Tik and Hassani, Ali and Orlov, Nikita and Shi, Humphrey},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2989--2998},
  year={2023}
}

%Segmentierung foundation model
@article{zou2023segment,
  title={Segment everything everywhere all at once},
  author={Zou, Xueyan and Yang, Jianwei and Zhang, Hao and Li, Feng and Li, Linjie and Wang, Jianfeng and Wang, Lijuan and Gao, Jianfeng and Lee, Yong Jae},
  journal={Advances in neural information processing systems},
  volume={36},
  pages={19769--19782},
  year={2023}
}

%Segmentierung foundation model
@inproceedings{wang2021max,
  title={Max-deeplab: End-to-end panoptic segmentation with mask transformers},
  author={Wang, Huiyu and Zhu, Yukun and Adam, Hartwig and Yuille, Alan and Chen, Liang-Chieh},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5463--5474},
  year={2021}
}


%Image foundation model, nicht ganz für Segmentierung gedacht
@inproceedings{wang2022ofa,
  title={Ofa: Unifying architectures, tasks, and modalities through a simple sequence-to-sequence learning framework},
  author={Wang, Peng and Yang, An and Men, Rui and Lin, Junyang and Bai, Shuai and Li, Zhikang and Ma, Jianxin and Zhou, Chang and Zhou, Jingren and Yang, Hongxia},
  booktitle={International conference on machine learning},
  pages={23318--23340},
  year={2022},
  organization={PMLR}
}

@article{stringer2021cellpose,
  title={Cellpose: a generalist algorithm for cellular segmentation},
  author={Stringer, Carsen and Wang, Tim and Michaelos, Michalis and Pachitariu, Marius},
  journal={Nature methods},
  volume={18},
  number={1},
  pages={100--106},
  year={2021},
  publisher={Nature Publishing Group US New York}
}

@article{pachitariu2025samcellpose,
  title={Cellpose-SAM: superhuman generalization for cellular segmentation},
  author={Pachitariu, Marius and Rariden, Michael and Stringer, Carsen},
  journal={bioRxiv},
  pages={2025--04},
  year={2025},
  publisher={Cold Spring Harbor Laboratory}
}

@article{vandeloo2025samfine,
  title={SAMCell: Generalized Label-Free Biological Cell Segmentation with Segment Anything},
  author={VandeLoo, Alexandra D and Malta, Nathan J and Aponte, Emilio and van Zyl, Caitlin and Xu, Danfei and Forest, Craig R},
  journal={bioRxiv},
  year={2025}
}

@article{archit2025samfine,
  title={Segment anything for microscopy},
  author={Archit, Anwai and Freckmann, Luca and Nair, Sushmita and Khalid, Nabeel and Hilt, Paul and Rajashekar, Vikas and Freitag, Marei and Teuber, Carolin and Buckley, Genevieve and von Haaren, Sebastian and others},
  journal={Nature Methods},
  pages={1--13},
  year={2025},
  publisher={Nature Publishing Group US New York}
}

@article{israel2023samfine,
  title={A foundation model for cell segmentation},
  author={Israel, Uriah and Marks, Markus and Dilip, Rohit and Li, Qilin and Schwartz, Morgan and Pradhan, Elora and Pao, Edward and Li, Shenyi and Pearson-Goulart, Alexander and Perona, Pietro and others},
  journal={arXiv preprint arXiv:2311.11004},
  year={2023}
}

@inproceedings{kirillov2023sam,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={4015--4026},
  year={2023}
}

@article{dippel2022segmentation,
  title={Transfer Learning for Segmentation Problems: Choose the Right Encoder and Skip the Decoder},
  author={Dippel, Jonas and Lenga, Matthias and Goerttler, Thomas and Obermayer, Klaus and H{\"o}hne, Johannes},
  journal={arXiv preprint arXiv:2207.14508},
  year={2022}
}

@article{bommasani2021foundationmodels,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@inproceedings{kirillov2019PQ,
  title={Panoptic segmentation},
  author={Kirillov, Alexander and He, Kaiming and Girshick, Ross and Rother, Carsten and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9404--9413},
  year={2019}
}

@article{li2024PartPQ,
  title={Panoptic-PartFormer++: A unified and decoupled view for panoptic part segmentation},
  author={Li, Xiangtai and Xu, Shilin and Yang, Yibo and Yuan, Haobo and Cheng, Guangliang and Tong, Yunhai and Lin, Zhouchen and Yang, Ming-Hsuan and Tao, Dacheng},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  year={2024},
  publisher={IEEE}
}

@inproceedings{fu2018cycleGAN,
  title={Three dimensional fluorescence microscopy image synthesis and segmentation},
  author={Fu, Chichen and Lee, Soonam and Joon Ho, David and Han, Shuo and Salama, Paul and Dunn, Kenneth W and Delp, Edward J},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition workshops},
  pages={2221--2229},
  year={2018}
}

@article{Kromp2020_Dataset,
  author = {Kromp, Florian and Bozsaky, Eva and Rifatbegovic, Fikret and Fischer, Lukas and Ambros, Magdalena and Berneder, Maria and Weiss, Tamara and Lazic, Daria and Doerr, Wolfgang and Hanbury, Allan and Beiske, Klaus and Ambros, Peter F. and Ambros, Inge M. and Taschner-Mandl, Sabine},
  journal = {Nature Scientific Data},
  title = {An annotated fluorescence image dataset for training nuclear segmentation methods},
  year = {2020},
  volume = {7},
  number = {262},
  pages = {1--8},
  doi = {10.1038/s41597-020-00608-w}
}

@article{chen20223_Dataset,
  title={3d ground truth annotations of nuclei in 3d microscopy volumes},
  author={Chen, Alain and Wu, Liming and Winfree, Seth and Dunn, Kenneth W and Salama, Paul and Delp, Edward J},
  journal={bioRxiv},
  pages={2022--09},
  year={2022},
  publisher={Cold Spring Harbor Laboratory}
}

@article{ulman2017cellTrackingChallenge,
  title={An objective comparison of cell-tracking algorithms},
  author={Ulman, Vladim{\'\i}r and Ma{\v{s}}ka, Martin and Magnusson, Klas EG and Ronneberger, Olaf and Haubold, Carsten and Harder, Nathalie and Matula, Pavel and Matula, Petr and Svoboda, David and Radojevic, Miroslav and others},
  journal={Nature methods},
  volume={14},
  number={12},
  pages={1141--1152},
  year={2017},
  publisher={Nature Publishing Group UK London}
}











@book{Boyd2009,
	author		= "Stephen Boyd and Lieven Vandenberghe",
	title		= "Convex {O}ptimization",
	edition		= "7th ed.",
	year		= "2009",
	publisher	= "Cambridge University Press",
	hyphenation     = "english",
}  

@online{EMVA1288,
	author		= "EMVA",
	title		= "{EMVA} {S}tandard 1288",
	subtitle	= "Standard for Characerization of Image Sensors and Cameras. Release 3.1.",
	url		= "http://www.emva.org/standards-technology/emva-1288/",
	version		= "3.1",
	date		= "2016",
	month		= "12",
	year		= "2016",
	hyphenation	= "ngerman",
} 

@online{Hashemi2018,
	title		= {Asymmetric Similarity Loss Function to Balance Precision and Recall in Highly Unbalanced Deep Medical Image Segmentation},
	author		= {Hashemi, S. R. and Salehi, S. S. M. and Erdogmus, D. and Prabhu, S. P. and Warfield S. K. and Gholipour, A.},
	year		= {2018},
	archivePrefix	= "arXiv",
	eprint		= {1803.11078v3},
	hyphenation     = "ngerman",
}

@book{Jaehne2012,
	author		= "Bernd Jähne",
	title		= "Digitale Bildverarbeitung und Bildgewinnung",
	edition		= "7. Auflage",
	year		= "2012",
	publisher	= "Springer",
	doi		= "10.1007/978-3-642-04952-1",
	hyphenation	= "ngerman",
}

@thesis{Scherr2017,
	author		= "Tim Scherr",
	title		= "Gradient-Based Surface Reconstruction and the Application to Wind Waves",
	type		= "Master's Thesis",
	institution	= "Ruprecht-Karls University Heidelberg",
	date		= "2017",
	doi		= "10.11588/heidok.00023653",
	hyphenation	= "english",
}

@thesis{Scherr2017-2,
	author		= "Tim Scherr",
	title		= "Gradient-Based Surface Reconstruction and the Application to Wind Waves",
	type		= "Master's Thesis",
	institution	= "Ruprecht-Karls University Heidelberg",
	date		= "2017",
	doi		= "10.11588/heidok.00023653",
	hyphenation	= "ngerman",
}

@article{Schott2018,
	author 		= "Schott, B. AND Traub, M. AND Schlagenhauf, C. AND Takamiya, M. AND Antritter, T. AND Bartschat, A. AND Löffler, K. AND Blessing, D. AND Otte, J. C. AND Kobitski, A. Y. AND Nienhaus, G. U. AND Strähle, U. AND Mikut, R. AND Stegmaier, J.",
	journal		= "PLOS Computational Biology",
	publisher	= "Public Library of Science",
	title		= "Embryo{M}iner: {A} {N}ew {F}ramework for {I}nteractive {K}nowledge {D}iscovery in {L}arge-{S}cale {C}ell {T}racking {D}ata of {D}eveloping {E}mbryos",
	year		= "2018",
	volume		= "14",
	pages		= "1-18",
	doi		= "10.1371/journal.pcbi.1006128",
	hyphenation	= "english",
}

@InProceedings{Szegedy2015,
	author		= {Szegedy, C. and Liu, W. and Jia, Y. and Sermanet, P. and Reed, S. and Anguelov, D. and Erhan, D. and Vanhoucke, V. and Rabinovich, A.},
	title		= {Going Deeper With Convolutions},
	booktitle	= {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages		= {1-9}, 
	year		= {2015},
	doi		= {10.1109/CVPR.2015.7298594}, 
	hyphenation	= "ngerman",
}  

@InProceedings{Radford2021,
  author    = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  date      = {2021-07},
  title     = {Learning {Transferable} {Visual} {Models} {From} {Natural} {Language} {Supervision}},
  language  = {en},
  pages     = {8748--8763},
  publisher = {PMLR},
  url       = {https://proceedings.mlr.press/v139/radford21a.html},
  urldate   = {2025-07-10},
  abstract  = {State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form of supervision limits their generality and usability since additional labeled data is needed to specify any other visual concept. Learning directly from raw text about images is a promising alternative which leverages a much broader source of supervision. We demonstrate that the simple pre-training task of predicting which caption goes with which image is an efficient and scalable way to learn SOTA image representations from scratch on a dataset of 400 million (image, text) pairs collected from the internet. After pre-training, natural language is used to reference learned visual concepts (or describe new ones) enabling zero-shot transfer of the model to downstream tasks. We study the performance of this approach by benchmarking on over 30 different existing computer vision datasets, spanning tasks such as OCR, action recognition in videos, geo-localization, and many types of fine-grained object classification. The model transfers non-trivially to most tasks and is often competitive with a fully supervised baseline without the need for any dataset specific training. For instance, we match the accuracy of the original ResNet-50 on ImageNet zero-shot without needing to use any of the 1.28 million training examples it was trained on.},
  file      = {Full Text PDF:http\://proceedings.mlr.press/v139/radford21a/radford21a.pdf:application/pdf;Supplementary PDF:http\://proceedings.mlr.press/v139/radford21a/radford21a-supp.pdf:application/pdf},
  issn      = {2640-3498},
}

@Comment{jabref-meta: databaseType:biblatex;}
